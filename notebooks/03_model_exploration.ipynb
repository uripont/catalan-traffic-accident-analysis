{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85565190",
   "metadata": {},
   "source": [
    "# 3 Model Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbad6a9a",
   "metadata": {},
   "source": [
    "## 3.1 Imports and dataset loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94866042",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, confusion_matrix, classification_report,\n",
    "    roc_curve, auc\n",
    ")\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set visualization defaults\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa6e8dd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded: 19701 rows, 41 columns\n"
     ]
    }
   ],
   "source": [
    "output_dir = '../output/'\n",
    "df = pd.read_csv(output_dir + 'df_cleaned.csv')\n",
    "print(f\"Dataset loaded: {df.shape[0]} rows, {df.shape[1]} columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "94aed8a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 19701 entries, 0 to 19700\n",
      "Data columns (total 41 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   Any                        19701 non-null  int64  \n",
      " 1   zona                       19701 non-null  int64  \n",
      " 2   nomCom                     19701 non-null  int64  \n",
      " 3   nomDem                     19701 non-null  int64  \n",
      " 4   F_MORTS                    19701 non-null  int64  \n",
      " 5   F_FERITS_GREUS             19701 non-null  int64  \n",
      " 6   F_FERITS_LLEUS             19701 non-null  int64  \n",
      " 7   F_VICTIMES                 19701 non-null  int64  \n",
      " 8   F_UNITATS_IMPLICADES       19701 non-null  int64  \n",
      " 9   F_VIANANTS_IMPLICADES      19701 non-null  int64  \n",
      " 10  F_BICICLETES_IMPLICADES    19701 non-null  int64  \n",
      " 11  F_CICLOMOTORS_IMPLICADES   19701 non-null  int64  \n",
      " 12  F_MOTOCICLETES_IMPLICADES  19701 non-null  int64  \n",
      " 13  F_VEH_LLEUGERS_IMPLICADES  19701 non-null  int64  \n",
      " 14  F_VEH_PESANTS_IMPLICADES   19701 non-null  int64  \n",
      " 15  C_VELOCITAT_VIA            19701 non-null  float64\n",
      " 16  D_BOIRA                    19701 non-null  int64  \n",
      " 17  D_CARACT_ENTORN            19701 non-null  int64  \n",
      " 18  D_CARRIL_ESPECIAL          19701 non-null  int64  \n",
      " 19  D_CIRCULACIO_MESURES_ESP   19701 non-null  int64  \n",
      " 20  D_CLIMATOLOGIA             19701 non-null  int64  \n",
      " 21  D_FUNC_ESP_VIA             19701 non-null  int64  \n",
      " 22  D_INTER_SECCIO             19701 non-null  int64  \n",
      " 23  D_LIMIT_VELOCITAT          19701 non-null  int64  \n",
      " 24  D_LLUMINOSITAT             19701 non-null  int64  \n",
      " 25  D_REGULACIO_PRIORITAT      19701 non-null  int64  \n",
      " 26  D_SENTITS_VIA              19701 non-null  int64  \n",
      " 27  D_SUBTIPUS_ACCIDENT        19701 non-null  int64  \n",
      " 28  D_SUBTIPUS_TRAM            19701 non-null  int64  \n",
      " 29  D_SUBZONA                  19701 non-null  int64  \n",
      " 30  D_SUPERFICIE               19701 non-null  int64  \n",
      " 31  D_TIPUS_VIA                19701 non-null  int64  \n",
      " 32  D_TITULARITAT_VIA          19701 non-null  int64  \n",
      " 33  D_TRACAT_ALTIMETRIC        19701 non-null  int64  \n",
      " 34  D_VENT                     19701 non-null  int64  \n",
      " 35  hor                        19701 non-null  float64\n",
      " 36  grupHor                    19701 non-null  int64  \n",
      " 37  tipAcc                     19701 non-null  int64  \n",
      " 38  tipDia                     19701 non-null  int64  \n",
      " 39  Mes                        19701 non-null  int64  \n",
      " 40  Mortalitat                 19701 non-null  int64  \n",
      "dtypes: float64(2), int64(39)\n",
      "memory usage: 6.2 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataset Info:\")\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f128a7bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Target variable distribution:\n",
      "Mortalitat\n",
      "0    16789\n",
      "1     2912\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Target proportions:\n",
      "Mortalitat\n",
      "0    0.85219\n",
      "1    0.14781\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTarget variable distribution:\")\n",
    "print(df['Mortalitat'].value_counts().sort_index())\n",
    "print(\"\\nTarget proportions:\")\n",
    "print(df['Mortalitat'].value_counts(normalize=True).sort_index())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da88bb18",
   "metadata": {},
   "source": [
    "## 3.2 Data preparation and splits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6ac338",
   "metadata": {},
   "source": [
    "### Separate features and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "95c952e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape: (19701, 40)\n",
      "Target shape: (19701,)\n",
      "\n",
      "Features (40 columns):\n",
      "['Any', 'zona', 'nomCom', 'nomDem', 'F_MORTS', 'F_FERITS_GREUS', 'F_FERITS_LLEUS', 'F_VICTIMES', 'F_UNITATS_IMPLICADES', 'F_VIANANTS_IMPLICADES', 'F_BICICLETES_IMPLICADES', 'F_CICLOMOTORS_IMPLICADES', 'F_MOTOCICLETES_IMPLICADES', 'F_VEH_LLEUGERS_IMPLICADES', 'F_VEH_PESANTS_IMPLICADES', 'C_VELOCITAT_VIA', 'D_BOIRA', 'D_CARACT_ENTORN', 'D_CARRIL_ESPECIAL', 'D_CIRCULACIO_MESURES_ESP', 'D_CLIMATOLOGIA', 'D_FUNC_ESP_VIA', 'D_INTER_SECCIO', 'D_LIMIT_VELOCITAT', 'D_LLUMINOSITAT', 'D_REGULACIO_PRIORITAT', 'D_SENTITS_VIA', 'D_SUBTIPUS_ACCIDENT', 'D_SUBTIPUS_TRAM', 'D_SUBZONA', 'D_SUPERFICIE', 'D_TIPUS_VIA', 'D_TITULARITAT_VIA', 'D_TRACAT_ALTIMETRIC', 'D_VENT', 'hor', 'grupHor', 'tipAcc', 'tipDia', 'Mes']\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(columns=['Mortalitat'])\n",
    "y = df['Mortalitat']\n",
    "\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")\n",
    "print(f\"\\nFeatures ({X.shape[1]} columns):\")\n",
    "print(X.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0de6b4",
   "metadata": {},
   "source": [
    "### Stratified Train/Val/Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fb2f8557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset splits:\n",
      "Train set: 13790 samples (70.0%)\n",
      "Val set:   2955 samples (15.0%)\n",
      "Test set:  2956 samples (15.0%)\n",
      "\n",
      "Class distribution across splits:\n",
      "\n",
      "Train:\n",
      "Mortalitat\n",
      "0    0.852212\n",
      "1    0.147788\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Val:\n",
      "Mortalitat\n",
      "0    0.852115\n",
      "1    0.147885\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Test:\n",
      "Mortalitat\n",
      "0    0.852165\n",
      "1    0.147835\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# First split: 70% train, 30% temp (for validation + test)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y, test_size=0.30, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Second split: 50% val, 50% test from temp\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.50, random_state=42, stratify=y_temp\n",
    ")\n",
    "\n",
    "print(\"Dataset splits:\")\n",
    "print(f\"Train set: {X_train.shape[0]} samples ({X_train.shape[0]/len(X)*100:.1f}%)\")\n",
    "print(f\"Val set:   {X_val.shape[0]} samples ({X_val.shape[0]/len(X)*100:.1f}%)\")\n",
    "print(f\"Test set:  {X_test.shape[0]} samples ({X_test.shape[0]/len(X)*100:.1f}%)\")\n",
    "\n",
    "print(\"\\nClass distribution across splits:\")\n",
    "print(\"\\nTrain:\")\n",
    "print(y_train.value_counts(normalize=True).sort_index())\n",
    "print(\"\\nVal:\")\n",
    "print(y_val.value_counts(normalize=True).sort_index())\n",
    "print(\"\\nTest:\")\n",
    "print(y_test.value_counts(normalize=True).sort_index())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd21ec6",
   "metadata": {},
   "source": [
    "### Feature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7aedb4b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features scaled using RobustScaler\n",
      "Train set shape: (13790, 40)\n",
      "Val set shape: (2955, 40)\n",
      "Test set shape: (2956, 40)\n"
     ]
    }
   ],
   "source": [
    "scaler = RobustScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Convert back to dfs\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns, index=X_train.index)\n",
    "X_val_scaled = pd.DataFrame(X_val_scaled, columns=X_val.columns, index=X_val.index)\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test.columns, index=X_test.index)\n",
    "\n",
    "print(\"Features scaled using RobustScaler\")\n",
    "print(f\"Train set shape: {X_train_scaled.shape}\")\n",
    "print(f\"Val set shape: {X_val_scaled.shape}\")\n",
    "print(f\"Test set shape: {X_test_scaled.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba56f03",
   "metadata": {},
   "source": [
    "### Class weights (for imbalanced data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ed07eb04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Weights (for handling imbalance):\n",
      "Class 0 (No mortality): 0.5867\n",
      "Class 1 (Mortality): 3.3832\n"
     ]
    }
   ],
   "source": [
    "class_weights = compute_class_weight(\n",
    "    'balanced',\n",
    "    classes=np.unique(y_train),\n",
    "    y=y_train\n",
    ")\n",
    "class_weight_dict = dict(zip(np.unique(y_train), class_weights))\n",
    "\n",
    "print(\"Class Weights (for handling imbalance):\")\n",
    "print(f\"Class 0 (No mortality): {class_weight_dict[0]:.4f}\")\n",
    "print(f\"Class 1 (Mortality): {class_weight_dict[1]:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "catalan-traffic-accident-analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
